{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ba3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json, os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "from transformers import AutoTokenizer, TFAutoModel, TFAutoModelForSequenceClassification #, BertModel, BertTokenizer, TFBertForSequenceClassification\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, \\\n",
    "roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool1D\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0e24c8",
   "metadata": {},
   "source": [
    "Set the seeder to have as stable random operations as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3cb5b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2010727",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf099bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_data = pd.read_csv('sequences_data.csv') # sequences of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a021b7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Vulnerability       Category  Length\n",
      "0              f\"str$id\"\"str$id\"\"str$id\"         ...  sql_injection       9\n",
      "1      client.listentcp()    proxy = proxy(proxy_...           xsrf       8\n",
      "2  from django.http import httpresponse, httpresp...  open_redirect       9\n",
      "3  def write_preset(conn, queryin, descriptin):\\t...  sql_injection     175\n",
      "4                          update_query = self.up...  sql_injection      14\n"
     ]
    }
   ],
   "source": [
    "print(sequences_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7aee574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Frequencies:\n",
      " sql_injection            1424\n",
      "xsrf                      976\n",
      "command_injection         721\n",
      "path_disclosure           481\n",
      "open_redirect             442\n",
      "remote_code_execution     334\n",
      "xss                       145\n",
      "Name: Category, dtype: int64\n",
      "Total samples  4523\n"
     ]
    }
   ],
   "source": [
    "label_frequencies = sequences_data['Category'].value_counts()\n",
    "print(\"Label Frequencies:\\n\", label_frequencies)\n",
    "print(\"Total samples \", len(sequences_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa5944e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sequences_data[\"Length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e6040f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of words: 392\n"
     ]
    }
   ],
   "source": [
    "word_counts = sequences_data[\"Vulnerability\"].apply(lambda x: len(x.split()))\n",
    "max_length = word_counts.max()\n",
    "print(\"Maximum number of words:\", max_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa5a91a",
   "metadata": {},
   "source": [
    "Pre-trained CodeBERT model - Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d13eeb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variation = \"microsoft/codebert-base-mlm\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_variation, do_lower_case=True)\n",
    "\n",
    "# Define New tokens for string and numerical i.e., strId$ and numId$\n",
    "new_tokens = [\"strId$\", \"numId$\"]\n",
    "for new_token in new_tokens:\n",
    "    if new_token not in tokenizer.get_vocab().keys():\n",
    "        tokenizer.add_tokens(new_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ac1d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user parameters\n",
    "n_epochs = 2\n",
    "batch_size = 2\n",
    "lr = 5e-05\n",
    "max_len = 512\n",
    "patience = 5\n",
    "train_len = 4000\n",
    "sequences_data = sequences_data.iloc[0:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c653c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = (true_positives + K.epsilon()) / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_metric(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = (true_positives + K.epsilon()) / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "\n",
    "    prec = precision_metric(y_true, y_pred)\n",
    "    rec = recall_metric(y_true, y_pred)\n",
    "    f1 = 2*((prec*rec)/(prec+rec+K.epsilon()))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab4fc2",
   "metadata": {},
   "source": [
    "Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc80f9",
   "metadata": {},
   "source": [
    "Binary Classification: Recognition of Injection Vulnerabilities (command_injection and sql_injection merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c64a1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to determine if the category is an injection or not\n",
    "# def is_injection(category):\n",
    "#     if category in ['sql_injection', 'command_injection']:\n",
    "#         return '1'\n",
    "#     else:\n",
    "#         return '0'\n",
    "\n",
    "# sequences_data['Injection'] = sequences_data['Category'].apply(is_injection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66ffd309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_categories = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afda43c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TFAutoModelForSequenceClassification.from_pretrained(model_variation, num_labels=n_categories)\n",
    "# # resize model embedding to match new tokenizer\n",
    "# model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af495c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_X(train_data_input, val_data_input, max_len):\n",
    "\n",
    "#     X_train = tokenizer(\n",
    "#         text=train_data_input,\n",
    "#         add_special_tokens=True,\n",
    "#         max_length=max_len,\n",
    "#         truncation=True,\n",
    "#         padding=True,\n",
    "#         return_tensors='tf',\n",
    "#         return_token_type_ids=False,\n",
    "#         return_attention_mask=True,\n",
    "#         verbose=True\n",
    "#     )\n",
    "\n",
    "#     X_test = tokenizer(\n",
    "#         text=val_data_input,\n",
    "#         add_special_tokens=True,\n",
    "#         max_length=max_len,\n",
    "#         truncation=True,\n",
    "#         padding=True,\n",
    "#         return_tensors='tf',\n",
    "#         return_token_type_ids=False,\n",
    "#         return_attention_mask=True,\n",
    "#         verbose=True\n",
    "#     )\n",
    "    \n",
    "#     return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a183507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test = tokenize_X(sequences_data[\"Vulnerability\"].tolist()[0:train_len], sequences_data[\"Vulnerability\"].tolist()[train_len:], max_len)\n",
    "\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b22edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(\n",
    "    learning_rate=lr, # HF recommendation\n",
    "    epsilon=1e-08,\n",
    "    decay=0.01,\n",
    "    clipnorm=1.0\n",
    ")\n",
    "\n",
    "loss = CategoricalCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "499ff9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     optimizer=optimizer,\n",
    "#     loss=loss,\n",
    "#     metrics=[f1_metric]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8afdf7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     x = {'input_ids':X_train['input_ids'], 'attention_mask':X_train['attention_mask']},\n",
    "#     y = to_categorical(sequences_data['Injection'].iloc[0:train_len]),\n",
    "#     validation_data = ({'input_ids':X_test['input_ids'], 'attention_mask':X_test['attention_mask']},\n",
    "#                         to_categorical(sequences_data['Injection'].iloc[train_len:].astype(int))),\n",
    "#     epochs=n_epochs,\n",
    "#     batch_size=batch_size\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3540490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['f1_metric'])\n",
    "# plt.plot(history.history['val_f1_metric'])\n",
    "# plt.ylabel('model f1_metric')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='best')\n",
    "# plt.savefig('train_history.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f04aafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = sequences_data['Injection'].iloc[train_len:].astype(int)\n",
    "# predicted = model.predict({'input_ids': X_test['input_ids'], 'attention_mask': X_test['attention_mask']}).logits\n",
    "# y_predicted = np.argmax(predicted, axis=1)\n",
    "# print(classification_report(targets, y_predicted))\n",
    "\n",
    "# tn, fp, fn, tp = confusion_matrix(targets, y_predicted).ravel()\n",
    "# acc=(tp+tn)/(tp+tn+fp+fn)\n",
    "# prec=tp/(tp+fp)\n",
    "# rec=tp/(tp+fn)\n",
    "# f1=2*prec*rec / (prec+rec)\n",
    "# print(\"Accuracy: \", acc)\n",
    "# print(\"Precision: \", prec)\n",
    "# print(\"Recall: \", rec)\n",
    "# print(\"F1-score: \", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "601b8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = sequences_data[\"Vulnerability\"].tolist()\n",
    "# y = sequences_data[\"Injection\"].tolist()\n",
    "\n",
    "# X = tokenizer(\n",
    "#         text=X[0:],\n",
    "#         add_special_tokens=True,\n",
    "#         max_length=max_len,\n",
    "#         truncation=True,\n",
    "#         padding=True,\n",
    "#         return_tensors='tf',\n",
    "#         return_token_type_ids=False,\n",
    "#         return_attention_mask=True,\n",
    "#         verbose=True\n",
    "#     )\n",
    "\n",
    "# y = np.array(y)\n",
    "\n",
    "# scores=['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "# values = [np.array([]) for i in range(0, len(scores))]\n",
    "# score_dict = OrderedDict(zip(scores, values))\n",
    "# k=10\n",
    "# f=0\n",
    "# kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "# nb_epoch = 100\n",
    "# BS = 64\n",
    "# print(\"Training...\")\n",
    "# milli_sec1 = int(round(time.time() * 1000))\n",
    "\n",
    "# for train_index, test_index in kfold.split(X['input_ids'].numpy(), y):\n",
    "#     f = f + 1\n",
    "#     print('fold number= ',f)\n",
    "    \n",
    "#     X_train_inputs, X_train_attention, X_test_inputs, X_test_attention = np.array(X['input_ids'])[train_index], np.array(X['attention_mask'])[train_index], np.array(X['input_ids'])[test_index], np.array(X['attention_mask'])[test_index]\n",
    "#     Y_train, Y_test = y[train_index], y[test_index]\n",
    "    \n",
    "# #         Y_train = np.array(Y_train)\n",
    "# #         Y_train = Y_train.ravel()\n",
    "# #         Y_test = np.array(Y_test)\n",
    "# #         Y_test = Y_test.ravel()\n",
    "\n",
    "# #         #sampling\n",
    "# #         X_res, Y_res = RandomOverSampler(random_state=seed, sampling_strategy=0.5).fit_resample(X_train, Y_train)\n",
    "# #         #X_res, Y_res = RandomUnderSampler(random_state=seed, sampling_strategy=0.5).fit_resample(X_train, Y_train)\n",
    "\n",
    "# #         #shuffle dataset\n",
    "# #         X_resampled=pd.DataFrame(X_res)\n",
    "# #         Y_resampled=pd.DataFrame(Y_res)\n",
    "# #         newTrain=X_resampled.assign(Label=Y_resampled.values)\n",
    "# #         newTrain = shuffle(newTrain,random_state=seed)\n",
    "# #         X_train=np.array(newTrain.iloc[:, 0:-1 ])\n",
    "# #         X_train=pd.DataFrame(X_train)\n",
    "# #         Y_train=np.array(newTrain.iloc[:, -1 ])\n",
    "# #         Y_train=pd.DataFrame(Y_train)\n",
    "\n",
    "#     model = TFAutoModelForSequenceClassification.from_pretrained(model_variation, num_labels=n_categories)\n",
    "#     # resize model embedding to match new tokenizer\n",
    "#     model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "#     model.compile(\n",
    "#         optimizer=optimizer,\n",
    "#         loss=loss,\n",
    "#         metrics=[f1_metric]\n",
    "#     )\n",
    "    \n",
    "#     history = model.fit(\n",
    "#         x = {'input_ids':X_train_inputs, 'attention_mask':X_train_attention},\n",
    "#         y = to_categorical(Y_train.astype(int)),\n",
    "#         validation_data = ({'input_ids':X_test_inputs, 'attention_mask':X_test_attention},\n",
    "#                             to_categorical(Y_test.astype(int))),\n",
    "#         epochs=n_epochs,\n",
    "#         batch_size=batch_size\n",
    "#     )\n",
    "\n",
    "#     predicted = model.predict({'input_ids': X_test['input_ids'], 'attention_mask': X_test['attention_mask']}).logits\n",
    "#     predictions = np.argmax(predicted, axis=1)\n",
    "    \n",
    "#     targets = Y_test.astype(int)\n",
    "    \n",
    "#     accuracy=accuracy_score(targets, predictions)\n",
    "#     precision=precision_score(targets, predictions)\n",
    "#     recall=recall_score(targets, predictions)\n",
    "#     f1=f1_score(targets, predictions)\n",
    "#     roc_auc=roc_auc_score(targets, predictions)\n",
    "#     print(confusion_matrix(targets, predictions, labels=[0, 1]))\n",
    "#     tn, fp, fn, tp = confusion_matrix(targets, predictions).ravel()\n",
    "#     acc = ((tp+tn)/(tp+tn+fp+fn))\n",
    "#     print(\"Accuracy:%.2f%%\"%(acc*100))\n",
    "#     print(\"Precision:%.2f%%\"%(precision*100))\n",
    "#     print(\"Recall:%.2f%%\"%(recall*100))\n",
    "#     print(\"F1 score:%.2f%%\"%(f1*100))\n",
    "#     print(\"Roc_Auc score:%.2f%%\"%(roc_auc*100))\n",
    "#     print(classification_report(targets, predictions))\n",
    "#     del model\n",
    "#     score_dict['accuracy'] = np.append(score_dict['accuracy'], accuracy)\n",
    "#     score_dict['precision'] = np.append(score_dict['precision'], precision)\n",
    "#     score_dict['recall'] = np.append(score_dict['recall'], recall)\n",
    "#     score_dict['f1'] = np.append(score_dict['f1'], f1)\n",
    "#     score_dict['roc_auc'] = np.append(score_dict['roc_auc'], roc_auc)\n",
    "\n",
    "# milli_sec2 = int(round(time.time() * 1000))\n",
    "# print(\"Cross Validation is completed after\", milli_sec2-milli_sec1)\n",
    "\n",
    "# print(\"accuracy: %.2f%% (%.2f%%)\" % (score_dict['accuracy'].mean()*100, score_dict['accuracy'].std()*100))\n",
    "# print(\"precision: %.2f%% (%.2f%%)\" % (score_dict['precision'].mean()*100, score_dict['precision'].std()*100))\n",
    "# print(\"recall: %.2f%% (%.2f%%)\" % (score_dict['recall'].mean()*100, score_dict['recall'].std()*100))\n",
    "# print(\"f1: %.2f%% (%.2f%%)\" % (score_dict['f1'].mean()*100, score_dict['f1'].std()*100))\n",
    "# print(\"roc_auc: %.2f%% (%.2f%%)\" % (score_dict['roc_auc'].mean()*100, score_dict['roc_auc'].std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbadb2b2",
   "metadata": {},
   "source": [
    "Multi-class Classification: Categorization of all detected vulnerabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b444655",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = len(label_frequencies) # 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d1281a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vulnerability</th>\n",
       "      <th>Category</th>\n",
       "      <th>Length</th>\n",
       "      <th>Category_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f\"str$id\"\"str$id\"\"str$id\"         ...</td>\n",
       "      <td>sql_injection</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>client.listentcp()    proxy = proxy(proxy_...</td>\n",
       "      <td>xsrf</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>from django.http import httpresponse, httpresp...</td>\n",
       "      <td>open_redirect</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def write_preset(conn, queryin, descriptin):\\t...</td>\n",
       "      <td>sql_injection</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>update_query = self.up...</td>\n",
       "      <td>sql_injection</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Vulnerability       Category  Length  \\\n",
       "0              f\"str$id\"\"str$id\"\"str$id\"         ...  sql_injection       9   \n",
       "1      client.listentcp()    proxy = proxy(proxy_...           xsrf       8   \n",
       "2  from django.http import httpresponse, httpresp...  open_redirect       9   \n",
       "3  def write_preset(conn, queryin, descriptin):\\t...  sql_injection     175   \n",
       "4                          update_query = self.up...  sql_injection      14   \n",
       "\n",
       "   Category_Index  \n",
       "0               0  \n",
       "1               1  \n",
       "2               2  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categories to numerical indexes\n",
    "category_numerical_indexes, unique_categories = sequences_data[\"Category\"].factorize()\n",
    "\n",
    "# Create a dictionary mapping each category to its numerical index\n",
    "category_to_index = {category: index for index, category in enumerate(unique_categories)}\n",
    "\n",
    "# Update the categories in the DataFrame with their numerical indexes\n",
    "sequences_data[\"Category_Index\"] = sequences_data[\"Category\"].map(category_to_index)\n",
    "sequences_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0d56181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxLen(X):\n",
    "\n",
    "    # Code for identifying max length of the data samples after tokenization using transformer tokenizer\n",
    "    \n",
    "    max_length = 0\n",
    "    # Iterate over each sample in your dataset\n",
    "    for i, input_ids in enumerate(X['input_ids']):\n",
    "        # Calculate the length of the tokenized sequence for the current sample\n",
    "        length = tf.math.reduce_sum(tf.cast(input_ids != 1, tf.int32)).numpy()\n",
    "        # Update max_length and max_row if the current length is greater\n",
    "        if length > max_length:\n",
    "            max_length = length\n",
    "            max_row = i\n",
    "\n",
    "    print(\"Max length of tokenized data:\", max_length)\n",
    "    print(\"Row with max length:\", max_row)\n",
    "\n",
    "    #X['input_ids'] = np.delete(X['input_ids'], max_row, axis=0)\n",
    "    \n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41097e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of tokenized data: 512\n",
      "Row with max length: 3\n",
      "Max tokenized length 512\n"
     ]
    }
   ],
   "source": [
    "X = sequences_data[\"Vulnerability\"].tolist()\n",
    "\n",
    "X = tokenizer(\n",
    "        text=X[0:],\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors='tf',\n",
    "        return_token_type_ids=False,\n",
    "        return_attention_mask=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "max_len = getMaxLen(X)\n",
    "print(\"Max tokenized length\", max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "fold number=  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base-mlm and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 458/2035 [=====>........................] - ETA: 6:41 - loss: 1.2286 - f1_metric: 0.5637"
     ]
    }
   ],
   "source": [
    "X = sequences_data[\"Vulnerability\"].tolist()\n",
    "y = sequences_data[\"Category_Index\"].tolist()\n",
    "\n",
    "X = tokenizer(\n",
    "        text=X[0:],\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors='tf',\n",
    "        return_token_type_ids=False,\n",
    "        return_attention_mask=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "\n",
    "scores=['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "values = [np.array([]) for i in range(0, len(scores))]\n",
    "score_dict = OrderedDict(zip(scores, values))\n",
    "k=10\n",
    "f=0\n",
    "kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "print(\"Training...\")\n",
    "milli_sec1 = int(round(time.time() * 1000))\n",
    "\n",
    "for train_index, test_index in kfold.split(X['input_ids'].numpy(), y):\n",
    "    f = f + 1\n",
    "    print('fold number= ',f)\n",
    "    \n",
    "    y = np.array(y)\n",
    "    \n",
    "    X_train_inputs, X_train_attention, X_test_inputs, X_test_attention = np.array(X['input_ids'])[train_index], np.array(X['attention_mask'])[train_index], np.array(X['input_ids'])[test_index], np.array(X['attention_mask'])[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "    \n",
    "#         Y_train = np.array(Y_train)\n",
    "#         Y_train = Y_train.ravel()\n",
    "#         Y_test = np.array(Y_test)\n",
    "#         Y_test = Y_test.ravel()\n",
    "\n",
    "#         #sampling\n",
    "#         X_res, Y_res = RandomOverSampler(random_state=seed, sampling_strategy=0.5).fit_resample(X_train, Y_train)\n",
    "#         #X_res, Y_res = RandomUnderSampler(random_state=seed, sampling_strategy=0.5).fit_resample(X_train, Y_train)\n",
    "\n",
    "#         #shuffle dataset\n",
    "#         X_resampled=pd.DataFrame(X_res)\n",
    "#         Y_resampled=pd.DataFrame(Y_res)\n",
    "#         newTrain=X_resampled.assign(Label=Y_resampled.values)\n",
    "#         newTrain = shuffle(newTrain,random_state=seed)\n",
    "#         X_train=np.array(newTrain.iloc[:, 0:-1 ])\n",
    "#         X_train=pd.DataFrame(X_train)\n",
    "#         Y_train=np.array(newTrain.iloc[:, -1 ])\n",
    "#         Y_train=pd.DataFrame(Y_train)\n",
    "\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_variation, num_labels=n_categories)\n",
    "    # resize model embedding to match new tokenizer\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=[f1_metric]\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "    model_checkpoint = ModelCheckpoint('./checkpoints/best_weights', monitor='val_loss', save_best_only=True)\n",
    "    \n",
    "    history = model.fit(\n",
    "        x = {'input_ids':X_train_inputs, 'attention_mask':X_train_attention},\n",
    "        y = to_categorical(Y_train.astype(int)),\n",
    "        validation_data = ({'input_ids':X_test_inputs, 'attention_mask':X_test_attention},\n",
    "                            to_categorical(Y_test.astype(int))),\n",
    "        epochs=n_epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "\n",
    "    #model.save_weights('./checkpoints/my_checkpoint')\n",
    "   \n",
    "    #model = TFAutoModelForSequenceClassification.from_pretrained(model_variation, num_labels=n_categories)\n",
    "    #model.resize_token_embeddings(len(tokenizer))\n",
    "    \n",
    "    model.load_weights('./checkpoints/best_weights')\n",
    "    \n",
    "    predicted = model.predict({'input_ids': X_test_inputs, 'attention_mask': X_test_attention}).logits\n",
    "    predictions = np.argmax(predicted, axis=1)\n",
    "    \n",
    "    targets = Y_test.astype(int)\n",
    "    \n",
    "    accuracy=accuracy_score(targets, predictions)\n",
    "    precision=precision_score(targets, predictions, average='micro')\n",
    "    recall=recall_score(targets, predictions, average='micro')\n",
    "    f1=f1_score(targets, predictions, average='micro')\n",
    "    conf_matrix = confusion_matrix(targets, predictions)\n",
    "                                   \n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    print(\"Accuracy:%.2f%%\"%(accuracy*100))\n",
    "    print(\"Precision:%.2f%%\"%(precision*100))\n",
    "    print(\"Recall:%.2f%%\"%(recall*100))\n",
    "    print(\"F1 score:%.2f%%\"%(f1*100))\n",
    "    \n",
    "    class_report = classification_report(targets, predictions)\n",
    "    print(\"Classification Report:\\n\", class_report)\n",
    "    \n",
    "    del model\n",
    "    score_dict['accuracy'] = np.append(score_dict['accuracy'], accuracy)\n",
    "    score_dict['precision'] = np.append(score_dict['precision'], precision)\n",
    "    score_dict['recall'] = np.append(score_dict['recall'], recall)\n",
    "    score_dict['f1'] = np.append(score_dict['f1'], f1)\n",
    "\n",
    "milli_sec2 = int(round(time.time() * 1000))\n",
    "print(\"Cross Validation is completed after\", milli_sec2-milli_sec1)\n",
    "\n",
    "print(\"accuracy: %.2f%% (%.2f%%)\" % (score_dict['accuracy'].mean()*100, score_dict['accuracy'].std()*100))\n",
    "print(\"precision: %.2f%% (%.2f%%)\" % (score_dict['precision'].mean()*100, score_dict['precision'].std()*100))\n",
    "print(\"recall: %.2f%% (%.2f%%)\" % (score_dict['recall'].mean()*100, score_dict['recall'].std()*100))\n",
    "print(\"f1: %.2f%% (%.2f%%)\" % (score_dict['f1'].mean()*100, score_dict['f1'].std()*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
